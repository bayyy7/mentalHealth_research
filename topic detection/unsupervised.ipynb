{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Username</th>\n",
       "      <th>Like Counts</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-02 20:59:07+00:00</td>\n",
       "      <td>Syar_bjm</td>\n",
       "      <td>3</td>\n",
       "      <td>@PangeranBiru212 @Samudera_Estu Knp hanya usta...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>kenapa hanya ustadz kenapa bukan guru yang tid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-10 04:50:26+00:00</td>\n",
       "      <td>Hazelnutxha</td>\n",
       "      <td>0</td>\n",
       "      <td>Replyannya bnrn darurat edukasi mental health ...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>replyannya bnrn darurat edukasi mental health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-14 22:44:42+00:00</td>\n",
       "      <td>wawanikip</td>\n",
       "      <td>0</td>\n",
       "      <td>Generasi melek mental health tapi gak ngerti a...</td>\n",
       "      <td>Youth</td>\n",
       "      <td>generasi melek mental health tapi gak mengerti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20 08:12:15+00:00</td>\n",
       "      <td>minkabora</td>\n",
       "      <td>0</td>\n",
       "      <td>@indomyfess Logikanya, siapa yang bener2 berju...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>logikanya siapa yang benar berjuang ga menyera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 14:21:33+00:00</td>\n",
       "      <td>wipilarpa</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalau lingkungan kerjanya sama kaya yg di Band...</td>\n",
       "      <td>Others</td>\n",
       "      <td>kalau lingkungan kerjanya sama kaya yang di ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-12-30 02:19:16+00:00</td>\n",
       "      <td>_Ahoyistired</td>\n",
       "      <td>0</td>\n",
       "      <td>Dah lama ye aku x pergi buat treatment mental ...</td>\n",
       "      <td>Service</td>\n",
       "      <td>deh lama ye aku x pergi buat treatment mental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-10-28 00:00:41+00:00</td>\n",
       "      <td>puppypuppiest</td>\n",
       "      <td>0</td>\n",
       "      <td>Pernah baca salah satu postingan dari kesehata...</td>\n",
       "      <td>Others</td>\n",
       "      <td>pernah baca salah satu postingan dari kesehata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-10-29 14:35:16+00:00</td>\n",
       "      <td>Ar1Nurdy</td>\n",
       "      <td>3</td>\n",
       "      <td>@idextratime Untuk decul se-Indonesia berterim...</td>\n",
       "      <td>Others</td>\n",
       "      <td>untuk decul se indonesia berterimakasih lah ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-12-16 05:39:36+00:00</td>\n",
       "      <td>ahmada_husein</td>\n",
       "      <td>3</td>\n",
       "      <td>@Lotusflower217 @notyourbunnybee @gkduluuuu Ng...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>tidak gitu kalau yang gudluking larinya ke mun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-11-04 05:44:07+00:00</td>\n",
       "      <td>moo_timomo</td>\n",
       "      <td>1</td>\n",
       "      <td>Minggu depan disuruh bawain training kesehatan...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>minggu depan disuruh bawain training kesehatan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime       Username  Like Counts  \\\n",
       "0  2022-11-02 20:59:07+00:00       Syar_bjm            3   \n",
       "1  2022-11-10 04:50:26+00:00    Hazelnutxha            0   \n",
       "2  2022-11-14 22:44:42+00:00      wawanikip            0   \n",
       "3  2022-12-20 08:12:15+00:00      minkabora            0   \n",
       "4  2022-12-01 14:21:33+00:00      wipilarpa            0   \n",
       "5  2022-12-30 02:19:16+00:00   _Ahoyistired            0   \n",
       "6  2022-10-28 00:00:41+00:00  puppypuppiest            0   \n",
       "7  2022-10-29 14:35:16+00:00       Ar1Nurdy            3   \n",
       "8  2022-12-16 05:39:36+00:00  ahmada_husein            3   \n",
       "9  2022-11-04 05:44:07+00:00     moo_timomo            1   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  @PangeranBiru212 @Samudera_Estu Knp hanya usta...   \n",
       "1  Replyannya bnrn darurat edukasi mental health ...   \n",
       "2  Generasi melek mental health tapi gak ngerti a...   \n",
       "3  @indomyfess Logikanya, siapa yang bener2 berju...   \n",
       "4  Kalau lingkungan kerjanya sama kaya yg di Band...   \n",
       "5  Dah lama ye aku x pergi buat treatment mental ...   \n",
       "6  Pernah baca salah satu postingan dari kesehata...   \n",
       "7  @idextratime Untuk decul se-Indonesia berterim...   \n",
       "8  @Lotusflower217 @notyourbunnybee @gkduluuuu Ng...   \n",
       "9  Minggu depan disuruh bawain training kesehatan...   \n",
       "\n",
       "                           Class  \\\n",
       "0  Feelings and Problematization   \n",
       "1  Feelings and Problematization   \n",
       "2                          Youth   \n",
       "3  Feelings and Problematization   \n",
       "4                         Others   \n",
       "5                        Service   \n",
       "6                         Others   \n",
       "7                         Others   \n",
       "8  Feelings and Problematization   \n",
       "9  Feelings and Problematization   \n",
       "\n",
       "                                           cleanText  \n",
       "0  kenapa hanya ustadz kenapa bukan guru yang tid...  \n",
       "1  replyannya bnrn darurat edukasi mental health ...  \n",
       "2  generasi melek mental health tapi gak mengerti...  \n",
       "3  logikanya siapa yang benar berjuang ga menyera...  \n",
       "4  kalau lingkungan kerjanya sama kaya yang di ba...  \n",
       "5  deh lama ye aku x pergi buat treatment mental ...  \n",
       "6  pernah baca salah satu postingan dari kesehata...  \n",
       "7  untuk decul se indonesia berterimakasih lah ke...  \n",
       "8  tidak gitu kalau yang gudluking larinya ke mun...  \n",
       "9  minggu depan disuruh bawain training kesehatan...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "workbook = openpyxl.load_workbook('../dataset/clean-2.xlsx')\n",
    "\n",
    "sheet = workbook.worksheets[0]\n",
    "\n",
    "df = []\n",
    "for row in sheet.iter_rows(values_only=True):\n",
    "    df.append(row)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(df[1:], columns=df[0])\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.Class != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_words = {\"amp;\": \"dan\", \"amp\": \"\", \"@\": \"di\", \"abis\": \"habis\", \"ad\": \"ada\", \"adlh\": \"adalah\", \"afaik\": \"as far as i know\", \"ahaha\": \"haha\", \"aj\": \"saja\", \"ajep-ajep\": \"dunia gemerlap\", \"ak\": \"saya\", \"akika\": \"aku\", \"akkoh\": \"aku\", \"akuwh\": \"aku\", \"alay\": \"norak\", \"alow\": \"halo\", \"ambilin\": \"ambilkan\", \"ancur\": \"hancur\", \"anjrit\": \"anjing\", \"anter\": \"antar\", \"ap2\": \"apa-apa\", \"apasih\": \"apa sih\", \"apes\": \"sial\", \"aps\": \"apa\", \"aq\": \"saya\", \"aquwh\": \"aku\", \"asbun\": \"asal bunyi\", \"aseekk\": \"asyik\", \"asekk\": \"asyik\", \"asem\": \"asam\", \"aspal\": \"asli tetapi palsu\", \"astul\": \"asal tulis\", \"ato\": \"atau\", \"au ah\": \"tidak mau tahu\", \"awak\": \"saya\", \"ay\": \"sayang\", \"ayank\": \"sayang\", \"b4\": \"sebelum\", \"bakalan\": \"akan\", \"bandes\": \"bantuan desa\", \"bangedh\": \"banget\", \"banpol\": \"bantuan polisi\", \"banpur\": \"bantuan tempur\", \"basbang\": \"basi\", \"bcanda\": \"bercanda\", \"bdg\": \"bandung\", \"begajulan\": \"nakal\", \"beliin\": \"belikan\", \"bencong\": \"banci\", \"bentar\": \"sebentar\", \"ber3\": \"bertiga\", \"beresin\": \"membereskan\", \"bete\": \"bosan\", \"beud\": \"banget\", \"bg\": \"abang\", \"bgmn\": \"bagaimana\", \"bgt\": \"banget\", \"bijimane\": \"bagaimana\", \"bintal\": \"bimbingan mental\", \"bkl\": \"akan\", \"bknnya\": \"bukannya\", \"blegug\": \"bodoh\", \"blh\": \"boleh\", \"bln\": \"bulan\", \"blum\": \"belum\", \"bnci\": \"benci\", \"bnran\": \"yang benar\", \"bodor\": \"lucu\", \"bokap\": \"ayah\", \"boker\": \"buang air besar\", \"bokis\": \"bohong\", \"boljug\": \"boleh juga\", \"bonek\": \"bocah nekat\", \"boyeh\": \"boleh\", \"br\": \"baru\", \"brg\": \"bareng\", \"bro\": \"saudara laki-laki\", \"bru\": \"baru\", \"bs\": \"bisa\", \"bsen\": \"bosan\", \"bt\": \"buat\", \"btw\": \"ngomong-ngomong\", \"buaya\": \"tidak setia\", \"bubbu\": \"tidur\", \"bubu\": \"tidur\", \"bumil\": \"ibu hamil\", \"bw\": \"bawa\", \"bwt\": \"buat\", \"byk\": \"banyak\", \"byrin\": \"bayarkan\", \"cabal\": \"sabar\", \"cadas\": \"keren\", \"calo\": \"makelar\", \"can\": \"belum\", \"capcus\": \"pergi\", \"caper\": \"cari perhatian\", \"ce\": \"cewek\", \"cekal\": \"cegah tangkal\", \"cemen\": \"penakut\", \"cengengesan\": \"tertawa\", \"cepet\": \"cepat\", \"cew\": \"cewek\", \"chuyunk\": \"sayang\", \"cimeng\": \"ganja\", \"cipika cipiki\": \"cium pipi kanan cium pipi kiri\", \"ciyh\": \"sih\", \"ckepp\": \"cakep\", \"ckp\": \"cakep\", \"cmiiw\": \"correct me if i'm wrong\", \"cmpur\": \"campur\", \"cong\": \"banci\", \"conlok\": \"cinta lokasi\", \"cowwyy\": \"maaf\", \"cp\": \"siapa\", \"cpe\": \"capek\", \"cppe\": \"capek\", \"cucok\": \"cocok\", \"cuex\": \"cuek\", \"cumi\": \"Cuma miscall\", \"cups\": \"culun\", \"curanmor\": \"pencurian kendaraan bermotor\", \"curcol\": \"curahan hati colongan\", \"cwek\": \"cewek\", \"cyin\": \"cinta\", \"d\": \"di\", \"dah\": \"deh\", \"dapet\": \"dapat\", \"de\": \"adik\", \"dek\": \"adik\", \"demen\": \"suka\", \"deyh\": \"deh\", \"dgn\": \"dengan\", \"diancurin\": \"dihancurkan\", \"dimaafin\": \"dimaafkan\", \"dimintak\": \"diminta\", \"disono\": \"di sana\", \"dket\": \"dekat\", \"dkk\": \"dan kawan-kawan\", \"dll\": \"dan lain-lain\", \"dlu\": \"dulu\", \"dngn\": \"dengan\", \"dodol\": \"bodoh\", \"doku\": \"uang\", \"dongs\": \"dong\", \"dpt\": \"dapat\", \"dri\": \"dari\", \"drmn\": \"darimana\", \"drtd\": \"dari tadi\", \"dst\": \"dan seterusnya\", \"dtg\": \"datang\", \"duh\": \"aduh\", \"duren\": \"durian\", \"ed\": \"edisi\", \"egp\": \"emang gue pikirin\", \"eke\": \"aku\", \"elu\": \"kamu\", \"emangnya\": \"memangnya\", \"emng\": \"memang\", \"endak\": \"tidak\", \"enggak\": \"tidak\", \"envy\": \"iri\", \"ex\": \"mantan\", \"fax\": \"facsimile\", \"fifo\": \"first in first out\", \"folbek\": \"follow back\", \"fyi\": \"sebagai informasi\", \"gaada\": \"tidak ada uang\", \"gag\": \"tidak\", \"gaje\": \"tidak jelas\", \"gak papa\": \"tidak apa-apa\", \"gan\": \"juragan\", \"gaptek\": \"gagap teknologi\", \"gatek\": \"gagap teknologi\", \"gawe\": \"kerja\", \"gbs\": \"tidak bisa\", \"gebetan\": \"orang yang disuka\", \"geje\": \"tidak jelas\", \"gepeng\": \"gelandangan dan pengemis\", \"ghiy\": \"lagi\", \"gile\": \"gila\", \"gimana\": \"bagaimana\", \"gino\": \"gigi nongol\", \"githu\": \"gitu\", \"gj\": \"tidak jelas\", \"gmana\": \"bagaimana\", \"gn\": \"begini\", \"goblok\": \"bodoh\", \"golput\": \"golongan putih\", \"gowes\": \"mengayuh sepeda\", \"gpny\": \"tidak punya\", \"gr\": \"gede rasa\", \"gretongan\": \"gratisan\", \"gtau\": \"tidak tahu\", \"gua\": \"saya\", \"guoblok\": \"goblok\", \"gw\": \"saya\", \"ha\": \"tertawa\", \"haha\": \"tertawa\", \"hallow\": \"halo\", \"hankam\": \"pertahanan dan keamanan\", \"hehe\": \"he\", \"helo\": \"halo\", \"hey\": \"hai\", \"hlm\": \"halaman\", \"hny\": \"hanya\", \"hoax\": \"isu bohong\", \"hr\": \"hari\", \"hrus\": \"harus\", \"hubdar\": \"perhubungan darat\", \"huff\": \"mengeluh\", \"hum\": \"rumah\", \"humz\": \"rumah\", \"ilang\": \"hilang\", \"ilfil\": \"tidak suka\", \"imho\": \"in my humble opinion\", \"imoetz\": \"imut\", \"item\": \"hitam\", \"itungan\": \"hitungan\", \"iye\": \"iya\", \"ja\": \"saja\", \"jadiin\": \"jadi\", \"jaim\": \"jaga image\", \"jayus\": \"tidak lucu\", \"jdi\": \"jadi\", \"jem\": \"jam\", \"jga\": \"juga\", \"jgnkan\": \"jangankan\", \"jir\": \"anjing\", \"jln\": \"jalan\", \"jomblo\": \"tidak punya pacar\", \"jubir\": \"juru bicara\", \"jutek\": \"galak\", \"k\": \"ke\", \"kab\": \"kabupaten\", \"kabor\": \"kabur\", \"kacrut\": \"kacau\", \"kadiv\": \"kepala divisi\", \"kagak\": \"tidak\", \"kalo\": \"kalau\", \"kampret\": \"sialan\", \"kamtibmas\": \"keamanan dan ketertiban masyarakat\", \"kamuwh\": \"kamu\", \"kanwil\": \"kantor wilayah\", \"karna\": \"karena\", \"kasubbag\": \"kepala subbagian\", \"katrok\": \"kampungan\", \"kayanya\": \"kayaknya\", \"kbr\": \"kabar\", \"kdu\": \"harus\", \"kec\": \"kecamatan\", \"kejurnas\": \"kejuaraan nasional\", \"kekeuh\": \"keras kepala\", \"kel\": \"kelurahan\", \"kemaren\": \"kemarin\", \"kepengen\": \"mau\", \"kepingin\": \"mau\", \"kepsek\": \"kepala sekolah\", \"kesbang\": \"kesatuan bangsa\", \"kesra\": \"kesejahteraan rakyat\", \"ketrima\": \"diterima\", \"kgiatan\": \"kegiatan\", \"kibul\": \"bohong\", \"kimpoi\": \"kawin\", \"kl\": \"kalau\", \"klianz\": \"kalian\", \"kloter\": \"kelompok terbang\", \"klw\": \"kalau\", \"km\": \"kamu\", \"kmps\": \"kampus\", \"kmrn\": \"kemarin\", \"knal\": \"kenal\", \"knp\": \"kenapa\", \"kodya\": \"kota madya\", \"komdis\": \"komisi disiplin\", \"komsov\": \"komunis sovyet\", \"kongkow\": \"kumpul bareng teman-teman\", \"kopdar\": \"kopi darat\", \"korup\": \"korupsi\", \"kpn\": \"kapan\", \"krenz\": \"keren\", \"krm\": \"kirim\", \"kt\": \"kita\", \"ktmu\": \"ketemu\", \"ktr\": \"kantor\", \"kuper\": \"kurang pergaulan\", \"kw\": \"imitasi\", \"kyk\": \"seperti\", \"la\": \"lah\", \"lam\": \"salam\", \"lamp\": \"lampiran\", \"lanud\": \"landasan udara\", \"latgab\": \"latihan gabungan\", \"lebay\": \"berlebihan\", \"leh\": \"boleh\", \"lelet\": \"lambat\", \"lemot\": \"lambat\", \"lgi\": \"lagi\", \"lgsg\": \"langsung\", \"liat\": \"lihat\", \"litbang\": \"penelitian dan pengembangan\", \"lmyn\": \"lumayan\", \"lo\": \"kamu\", \"loe\": \"kamu\", \"lola\": \"lambat berfikir\", \"louph\": \"cinta\", \"low\": \"kalau\", \"lp\": \"lupa\", \"luber\": \"langsung, umum, bebas, dan rahasia\", \"luchuw\": \"lucu\", \"lum\": \"belum\", \"luthu\": \"lucu\", \"lwn\": \"lawan\", \"maacih\": \"terima kasih\", \"mabal\": \"bolos\", \"macem\": \"macam\", \"macih\": \"masih\", \"maem\": \"makan\", \"magabut\": \"makan gaji buta\", \"maho\": \"homo\", \"mak jang\": \"kaget\", \"maksain\": \"memaksa\", \"malem\": \"malam\", \"mam\": \"makan\", \"maneh\": \"kamu\", \"maniez\": \"manis\", \"mao\": \"mau\", \"masukin\": \"masukkan\", \"melu\": \"ikut\", \"mepet\": \"dekat sekali\", \"mgu\": \"minggu\", \"migas\": \"minyak dan gas bumi\", \"mikol\": \"minuman beralkohol\", \"miras\": \"minuman keras\", \"mlah\": \"malah\", \"mngkn\": \"mungkin\", \"mo\": \"mau\", \"mokad\": \"mati\", \"moso\": \"masa\", \"mpe\": \"sampai\", \"msk\": \"masuk\", \"mslh\": \"masalah\", \"mt\": \"makan teman\", \"mubes\": \"musyawarah besar\", \"mulu\": \"melulu\", \"mumpung\": \"selagi\", \"munas\": \"musyawarah nasional\", \"muntaber\": \"muntah dan berak\", \"musti\": \"mesti\", \"muupz\": \"maaf\", \"mw\": \"now watching\", \"n\": \"dan\", \"nanam\": \"menanam\", \"nanya\": \"bertanya\", \"napa\": \"kenapa\", \"napi\": \"narapidana\", \"napza\": \"narkotika, alkohol, psikotropika, dan zat adiktif \", \"narkoba\": \"narkotika, psikotropika, dan obat terlarang\", \"nasgor\": \"nasi goreng\", \"nda\": \"tidak\", \"ndiri\": \"sendiri\", \"ne\": \"ini\", \"nekolin\": \"neokolonialisme\", \"nembak\": \"menyatakan cinta\", \"ngabuburit\": \"menunggu berbuka puasa\", \"ngaku\": \"mengaku\", \"ngambil\": \"mengambil\", \"nganggur\": \"tidak punya pekerjaan\", \"ngapah\": \"kenapa\", \"ngaret\": \"terlambat\", \"ngasih\": \"memberikan\", \"ngebandel\": \"berbuat bandel\", \"ngegosip\": \"bergosip\", \"ngeklaim\": \"mengklaim\", \"ngeksis\": \"menjadi eksis\", \"ngeles\": \"berkilah\", \"ngelidur\": \"menggigau\", \"ngerampok\": \"merampok\", \"ngga\": \"tidak\", \"ngibul\": \"berbohong\", \"ngiler\": \"mau\", \"ngiri\": \"iri\", \"ngisiin\": \"mengisikan\", \"ngmng\": \"bicara\", \"ngomong\": \"bicara\", \"ngubek2\": \"mencari-cari\", \"ngurus\": \"mengurus\", \"nie\": \"ini\", \"nih\": \"ini\", \"niyh\": \"nih\", \"nmr\": \"nomor\", \"nntn\": \"nonton\", \"nobar\": \"nonton bareng\", \"np\": \"now playing\", \"ntar\": \"nanti\", \"ntn\": \"nonton\", \"numpuk\": \"bertumpuk\", \"nutupin\": \"menutupi\", \"nyari\": \"mencari\", \"nyekar\": \"menyekar\", \"nyicil\": \"mencicil\", \"nyoblos\": \"mencoblos\", \"nyokap\": \"ibu\", \"ogah\": \"tidak mau\", \"ol\": \"online\", \"ongkir\": \"ongkos kirim\", \"oot\": \"out of topic\", \"org2\": \"orang-orang\", \"ortu\": \"orang tua\", \"otda\": \"otonomi daerah\", \"otw\": \"on the way, sedang di jalan\", \"pacal\": \"pacar\", \"pake\": \"pakai\", \"pala\": \"kepala\", \"pansus\": \"panitia khusus\", \"parpol\": \"partai politik\", \"pasutri\": \"pasangan suami istri\", \"pd\": \"pada\", \"pede\": \"percaya diri\", \"pelatnas\": \"pemusatan latihan nasional\", \"pemda\": \"pemerintah daerah\", \"pemkot\": \"pemerintah kota\", \"pemred\": \"pemimpin redaksi\", \"penjas\": \"pendidikan jasmani\", \"perda\": \"peraturan daerah\", \"perhatiin\": \"perhatikan\", \"pesenan\": \"pesanan\", \"pgang\": \"pegang\", \"pi\": \"tapi\", \"pilkada\": \"pemilihan kepala daerah\", \"pisan\": \"sangat\", \"pk\": \"penjahat kelamin\", \"plg\": \"paling\", \"pmrnth\": \"pemerintah\", \"polantas\": \"polisi lalu lintas\", \"ponpes\": \"pondok pesantren\", \"pp\": \"pulang pergi\", \"prg\": \"pergi\", \"prnh\": \"pernah\", \"psen\": \"pesan\", \"pst\": \"pasti\", \"pswt\": \"pesawat\", \"pw\": \"posisi nyaman\", \"qmu\": \"kamu\", \"rakor\": \"rapat koordinasi\", \"ranmor\": \"kendaraan bermotor\", \"re\": \"reply\", \"ref\": \"referensi\", \"rehab\": \"rehabilitasi\", \"rempong\": \"sulit\", \"repp\": \"balas\", \"restik\": \"reserse narkotika\", \"rhs\": \"rahasia\", \"rmh\": \"rumah\", \"ru\": \"baru\", \"ruko\": \"rumah toko\", \"rusunawa\": \"rumah susun sewa\", \"ruz\": \"terus\", \"saia\": \"saya\", \"skg\": \"sekarang\", \"skrg\": \"sekarang\", \"skrng\": \"sekarang\", \"salting\": \"salah tingkah\", \"sampe\": \"sampai\", \"samsek\": \"sama sekali\", \"sapose\": \"siapa\", \"satpam\": \"satuan pengamanan\", \"sbb\": \"sebagai berikut\", \"sbh\": \"sebuah\", \"sbnrny\": \"sebenarnya\", \"scr\": \"secara\", \"sdgkn\": \"sedangkan\", \"sdkt\": \"sedikit\", \"se7\": \"setuju\", \"sebelas dua belas\": \"mirip\", \"sembako\": \"sembilan bahan pokok\", \"sempet\": \"sempat\", \"sendratari\": \"seni drama tari\", \"sgt\": \"sangat\", \"shg\": \"sehingga\", \"siech\": \"sih\", \"sikon\": \"situasi dan kondisi\", \"sinetron\": \"sinema elektronik\", \"siramin\": \"siramkan\", \"sj\": \"saja\", \"skalian\": \"sekalian\", \"sklh\": \"sekolah\", \"skt\": \"sakit\", \"slesai\": \"selesai\", \"sll\": \"selalu\", \"slma\": \"selama\", \"slsai\": \"selesai\", \"smpt\": \"sempat\", \"smw\": \"semua\", \"sndiri\": \"sendiri\", \"soljum\": \"sholat jumat\", \"songong\": \"sombong\", \"sory\": \"maaf\", \"sosek\": \"sosial-ekonomi\", \"sotoy\": \"sok tahu\", \"spa\": \"siapa\", \"sppa\": \"siapa\", \"spt\": \"seperti\", \"srtfkt\": \"sertifikat\", \"stiap\": \"setiap\", \"stlh\": \"setelah\", \"suk\": \"masuk\", \"sumpek\": \"sempit\", \"syg\": \"sayang\", \"t4\": \"tempat\", \"tajir\": \"kaya\", \"tau\": \"tahu\", \"taw\": \"tahu\", \"td\": \"tadi\", \"tdk\": \"tidak\", \"teh\": \"kakak perempuan\", \"telat\": \"terlambat\", \"telmi\": \"telat berpikir\", \"temen\": \"teman\", \"tengil\": \"menyebalkan\", \"tepar\": \"terkapar\", \"tggu\": \"tunggu\", \"tgu\": \"tunggu\", \"thankz\": \"terima kasih\", \"thn\": \"tahun\", \"tilang\": \"bukti pelanggaran\", \"tipiwan\": \"TvOne\", \"tks\": \"terima kasih\", \"tlp\": \"telepon\", \"tls\": \"tulis\", \"tmbah\": \"tambah\", \"tmen2\": \"teman-teman\", \"tmpah\": \"tumpah\", \"tmpt\": \"tempat\", \"tngu\": \"tunggu\", \"tnyta\": \"ternyata\", \"tokai\": \"tai\", \"toserba\": \"toko serba ada\", \"tpi\": \"tapi\", \"trdhulu\": \"terdahulu\", \"trima\": \"terima kasih\", \"trm\": \"terima\", \"trs\": \"terus\", \"trutama\": \"terutama\", \"ts\": \"penulis\", \"tst\": \"tahu sama tahu\", \"ttg\": \"tentang\", \"tuch\": \"tuh\", \"tuir\": \"tua\", \"tw\": \"tahu\", \"u\": \"kamu\", \"ud\": \"sudah\", \"udah\": \"sudah\", \"ujg\": \"ujung\", \"ul\": \"ulangan\", \"unyu\": \"lucu\", \"uplot\": \"unggah\", \"urang\": \"saya\", \"usah\": \"perlu\", \"utk\": \"untuk\", \"valas\": \"valuta asing\", \"w/\": \"dengan\", \"wadir\": \"wakil direktur\", \"wamil\": \"wajib militer\", \"warkop\": \"warung kopi\", \"warteg\": \"warung tegal\", \"wat\": \"buat\", \"wkt\": \"waktu\", \"wtf\": \"what the fuck\", \"xixixi\": \"tertawa\", \"ya\": \"iya\", \"yap\": \"iya\", \"yaudah\": \"ya sudah\", \"yawdah\": \"ya sudah\", \"yg\": \"yang\", \"yl\": \"yang lain\", \"yo\": \"iya\", \"yowes\": \"ya sudah\", \"yup\": \"iya\", \"7an\": \"tujuan\", \"ababil\": \"abg labil\", \"acc\": \"accord\", \"adlah\": \"adalah\", \"adoh\": \"aduh\", \"aha\": \"tertawa\", \"aing\": \"saya\", \"aja\": \"saja\", \"ajj\": \"saja\", \"aka\": \"dikenal juga sebagai\", \"akko\": \"aku\", \"akku\": \"aku\", \"akyu\": \"aku\", \"aljasa\": \"asal jadi saja\", \"ama\": \"sama\", \"ambl\": \"ambil\", \"anjir\": \"anjing\", \"ank\": \"anak\", \"ap\": \"apa\", \"apaan\": \"apa\", \"ape\": \"apa\", \"aplot\": \"unggah\", \"apva\": \"apa\", \"aqu\": \"aku\", \"asap\": \"sesegera mungkin\", \"aseek\": \"asyik\", \"asek\": \"asyik\", \"aseknya\": \"asyiknya\", \"asoy\": \"asyik\", \"astrojim\": \"astagfirullahaladzim\", \"ath\": \"kalau begitu\", \"atuh\": \"kalau begitu\", \"ava\": \"avatar\", \"aws\": \"awas\", \"ayang\": \"sayang\", \"ayok\": \"ayo\", \"bacot\": \"banyak bicara\", \"bales\": \"balas\", \"bangdes\": \"pembangunan desa\", \"bangkotan\": \"tua\", \"banpres\": \"bantuan presiden\", \"bansarkas\": \"bantuan sarana kesehatan\", \"bazis\": \"badan amal, zakat, infak, dan sedekah\", \"bcoz\": \"karena\", \"beb\": \"sayang\", \"bejibun\": \"banyak\", \"belom\": \"belum\", \"bener\": \"benar\", \"ber2\": \"berdua\", \"berdikari\": \"berdiri di atas kaki sendiri\", \"bet\": \"banget\", \"beti\": \"beda tipis\", \"beut\": \"banget\", \"bgd\": \"banget\", \"bgs\": \"bagus\", \"bhubu\": \"tidur\", \"bimbuluh\": \"bimbingan dan penyuluhan\", \"bisi\": \"kalau-kalau\", \"bkn\": \"bukan\", \"bl\": \"beli\", \"blg\": \"bilang\", \"blm\": \"belum\", \"bls\": \"balas\", \"bnchi\": \"benci\", \"bngung\": \"bingung\", \"bnyk\": \"banyak\", \"bohay\": \"badan aduhai\", \"bokep\": \"porno\", \"bokin\": \"pacar\", \"bole\": \"boleh\", \"bolot\": \"bodoh\", \"bonyok\": \"ayah ibu\", \"bpk\": \"bapak\", \"brb\": \"segera kembali\", \"brngkt\": \"berangkat\", \"brp\": \"berapa\", \"brur\": \"saudara laki-laki\", \"bsa\": \"bisa\", \"bsk\": \"besok\", \"bu_bu\": \"tidur\", \"bubarin\": \"bubarkan\", \"buber\": \"buka bersama\", \"bujubune\": \"luar biasa\", \"buser\": \"buru sergap\", \"bwhn\": \"bawahan\", \"byar\": \"bayar\", \"byr\": \"bayar\", \"c8\": \"chat\", \"cabut\": \"pergi\", \"caem\": \"cakep\", \"cama-cama\": \"sama-sama\", \"cangcut\": \"celana dalam\", \"cape\": \"capek\", \"caur\": \"jelek\", \"cekak\": \"tidak ada uang\", \"cekidot\": \"coba lihat\", \"cemplungin\": \"cemplungkan\", \"ceper\": \"pendek\", \"ceu\": \"kakak perempuan\", \"cewe\": \"cewek\", \"cibuk\": \"sibuk\", \"cin\": \"cinta\", \"ciye\": \"cie\", \"ckck\": \"ck\", \"clbk\": \"cinta lama bersemi kembali\", \"cmpr\": \"campur\", \"cnenk\": \"senang\", \"congor\": \"mulut\", \"cow\": \"cowok\", \"coz\": \"karena\", \"cpa\": \"siapa\", \"gokil\": \"gila\", \"gombal\": \"suka merayu\", \"gpl\": \"tidak pakai lama\", \"gpp\": \"tidak apa-apa\", \"gretong\": \"gratis\", \"gt\": \"begitu\", \"gtw\": \"tidak tahu\", \"gue\": \"saya\", \"guys\": \"teman-teman\", \"gws\": \"cepat sembuh\", \"haghaghag\": \"tertawa\", \"hakhak\": \"tertawa\", \"handak\": \"bahan peledak\", \"hansip\": \"pertahanan sipil\", \"hellow\": \"halo\", \"helow\": \"halo\", \"hi\": \"hai\", \"hlng\": \"hilang\", \"hnya\": \"hanya\", \"houm\": \"rumah\", \"hrs\": \"harus\", \"hubad\": \"hubungan angkatan darat\", \"hubla\": \"perhubungan laut\", \"huft\": \"mengeluh\", \"humas\": \"hubungan masyarakat\", \"idk\": \"saya tidak tahu\", \"ilfeel\": \"tidak suka\", \"imba\": \"jago sekali\", \"imoet\": \"imut\", \"info\": \"informasi\", \"itung\": \"hitung\", \"isengin\": \"bercanda\", \"iyala\": \"iya lah\", \"iyo\": \"iya\", \"jablay\": \"jarang dibelai\", \"jadul\": \"jaman dulu\", \"jancuk\": \"anjing\", \"jd\": \"jadi\", \"jdikan\": \"jadikan\", \"jg\": \"juga\", \"jgn\": \"jangan\", \"jijay\": \"jijik\", \"jkt\": \"jakarta\", \"jnj\": \"janji\", \"jth\": \"jatuh\", \"jurdil\": \"jujur adil\", \"jwb\": \"jawab\", \"ka\": \"kakak\", \"kabag\": \"kepala bagian\", \"kacian\": \"kasihan\", \"kadit\": \"kepala direktorat\", \"kaga\": \"tidak\", \"kaka\": \"kakak\", \"kamtib\": \"keamanan dan ketertiban\", \"kamuh\": \"kamu\", \"kamyu\": \"kamu\", \"kapt\": \"kapten\", \"kasat\": \"kepala satuan\", \"kasubbid\": \"kepala subbidang\", \"kau\": \"kamu\", \"kbar\": \"kabar\", \"kcian\": \"kasihan\", \"keburu\": \"terlanjur\", \"kedubes\": \"kedutaan besar\", \"kek\": \"seperti\", \"keknya\": \"kayaknya\", \"keliatan\": \"kelihatan\", \"keneh\": \"masih\", \"kepikiran\": \"terpikirkan\", \"kepo\": \"mau tahu urusan orang\", \"kere\": \"tidak punya uang\", \"kesian\": \"kasihan\", \"ketauan\": \"ketahuan\", \"keukeuh\": \"keras kepala\", \"khan\": \"kan\", \"kibus\": \"kaki busuk\", \"kk\": \"kakak\", \"klian\": \"kalian\", \"klo\": \"kalau\", \"kluarga\": \"keluarga\", \"klwrga\": \"keluarga\", \"kmari\": \"kemari\", \"kmpus\": \"kampus\", \"kn\": \"kan\", \"knl\": \"kenal\", \"knpa\": \"kenapa\", \"kog\": \"kok\", \"kompi\": \"komputer\", \"komtiong\": \"komunis Tiongkok\", \"konjen\": \"konsulat jenderal\", \"koq\": \"kok\", \"kpd\": \"kepada\", \"kptsan\": \"keputusan\", \"krik\": \"garing\", \"krn\": \"karena\", \"ktauan\": \"ketahuan\", \"ktny\": \"katanya\", \"kudu\": \"harus\", \"kuq\": \"kok\", \"ky\": \"seperti\", \"kykny\": \"kayanya\", \"laka\": \"kecelakaan\", \"lambreta\": \"lambat\", \"lansia\": \"lanjut usia\", \"lapas\": \"lembaga pemasyarakatan\", \"lbur\": \"libur\", \"lekong\": \"laki-laki\", \"lg\": \"lagi\", \"lgkp\": \"lengkap\", \"lht\": \"lihat\", \"linmas\": \"perlindungan masyarakat\", \"lmyan\": \"lumayan\", \"lngkp\": \"lengkap\", \"loch\": \"loh\", \"lol\": \"tertawa\", \"lom\": \"belum\", \"loupz\": \"cinta\", \"lowh\": \"kamu\", \"lu\": \"kamu\", \"luchu\": \"lucu\", \"luff\": \"cinta\", \"luph\": \"cinta\", \"lw\": \"kamu\", \"lwt\": \"lewat\", \"maaciw\": \"terima kasih\", \"mabes\": \"markas besar\", \"macem-macem\": \"macam-macam\", \"madesu\": \"masa depan suram\", \"maen\": \"main\", \"mahatma\": \"maju sehat bersama\", \"mak\": \"ibu\", \"makasih\": \"terima kasih\", \"malah\": \"bahkan\", \"malu2in\": \"memalukan\", \"mamz\": \"makan\", \"manies\": \"manis\", \"mantep\": \"mantap\", \"markus\": \"makelar kasus\", \"mba\": \"mbak\", \"mending\": \"lebih baik\", \"mgkn\": \"mungkin\", \"mhn\": \"mohon\", \"miker\": \"minuman keras\", \"milis\": \"mailing list\", \"mksd\": \"maksud\", \"mls\": \"malas\", \"mnt\": \"minta\", \"moge\": \"motor gede\", \"mokat\": \"mati\", \"mosok\": \"masa\", \"msh\": \"masih\", \"mskpn\": \"meskipun\", \"msng2\": \"masing-masing\", \"muahal\": \"mahal\", \"muker\": \"musyawarah kerja\", \"mumet\": \"pusing\", \"muna\": \"munafik\", \"munaslub\": \"musyawarah nasional luar biasa\", \"musda\": \"musyawarah daerah\", \"muup\": \"maaf\", \"muuv\": \"maaf\", \"nal\": \"kenal\", \"nangis\": \"menangis\", \"naon\": \"apa\", \"napol\": \"narapidana politik\", \"naq\": \"anak\", \"narsis\": \"bangga pada diri sendiri\", \"nax\": \"anak\", \"ndak\": \"tidak\", \"ndut\": \"gendut\", \"nekolim\": \"neokolonialisme\", \"nelfon\": \"menelepon\", \"ngabis2in\": \"menghabiskan\", \"ngakak\": \"tertawa\", \"ngambek\": \"marah\", \"ngampus\": \"pergi ke kampus\", \"ngantri\": \"mengantri\", \"ngapain\": \"sedang apa\", \"ngaruh\": \"berpengaruh\", \"ngawur\": \"berbicara sembarangan\", \"ngeceng\": \"kumpul bareng-bareng\", \"ngeh\": \"sadar\", \"ngekos\": \"tinggal di kos\", \"ngelamar\": \"melamar\", \"ngeliat\": \"melihat\", \"ngemeng\": \"bicara terus-terusan\", \"ngerti\": \"mengerti\", \"nggak\": \"tidak\", \"ngikut\": \"ikut\", \"nginep\": \"menginap\", \"ngisi\": \"mengisi\", \"ngmg\": \"bicara\", \"ngocol\": \"lucu\", \"ngomongin\": \"membicarakan\", \"ngumpul\": \"berkumpul\", \"ni\": \"ini\", \"nyasar\": \"tersesat\", \"nyariin\": \"mencari\", \"nyiapin\": \"mempersiapkan\", \"nyiram\": \"menyiram\", \"nyok\": \"ayo\", \"o/\": \"oleh\", \"ok\": \"ok\", \"priksa\": \"periksa\", \"pro\": \"profesional\", \"psn\": \"pesan\", \"psti\": \"pasti\", \"puanas\": \"panas\", \"qmo\": \"kamu\", \"qt\": \"kita\", \"rame\": \"ramai\", \"raskin\": \"rakyat miskin\", \"red\": \"redaksi\", \"reg\": \"register\", \"rejeki\": \"rezeki\", \"renstra\": \"rencana strategis\", \"reskrim\": \"reserse kriminal\", \"sni\": \"sini\", \"somse\": \"sombong sekali\", \"sorry\": \"maaf\", \"sosbud\": \"sosial-budaya\", \"sospol\": \"sosial-politik\", \"sowry\": \"maaf\", \"spd\": \"sepeda\", \"sprti\": \"seperti\", \"spy\": \"supaya\", \"stelah\": \"setelah\", \"subbag\": \"subbagian\", \"sumbangin\": \"sumbangkan\", \"sy\": \"saya\", \"syp\": \"siapa\", \"tabanas\": \"tabungan pembangunan nasional\", \"tar\": \"nanti\", \"taun\": \"tahun\", \"tawh\": \"tahu\", \"tdi\": \"tadi\", \"te2p\": \"tetap\", \"tekor\": \"rugi\", \"telkom\": \"telekomunikasi\", \"telp\": \"telepon\", \"temen2\": \"teman-teman\", \"tengok\": \"menjenguk\", \"terbitin\": \"terbitkan\", \"tgl\": \"tanggal\", \"thanks\": \"terima kasih\", \"thd\": \"terhadap\", \"thx\": \"terima kasih\", \"tipi\": \"TV\", \"tkg\": \"tukang\", \"tll\": \"terlalu\", \"tlpn\": \"telepon\", \"tman\": \"teman\", \"tmbh\": \"tambah\", \"tmn2\": \"teman-teman\", \"tmph\": \"tumpah\", \"tnda\": \"tanda\", \"tnh\": \"tanah\", \"togel\": \"toto gelap\", \"tp\": \"tapi\", \"tq\": \"terima kasih\", \"trgntg\": \"tergantung\", \"trims\": \"terima kasih\", \"cb\": \"coba\", \"y\": \"ya\", \"munfik\": \"munafik\", \"reklamuk\": \"reklamasi\", \"sma\": \"sama\", \"tren\": \"trend\", \"ngehe\": \"kesal\", \"mz\": \"mas\", \"analisise\": \"analisis\", \"sadaar\": \"sadar\", \"sept\": \"september\", \"nmenarik\": \"menarik\", \"zonk\": \"bodoh\", \"rights\": \"benar\", \"simiskin\": \"miskin\", \"ngumpet\": \"sembunyi\", \"hardcore\": \"keras\", \"akhirx\": \"akhirnya\", \"solve\": \"solusi\", \"watuk\": \"batuk\", \"ngebully\": \"intimidasi\", \"masy\": \"masyarakat\", \"still\": \"masih\", \"tauk\": \"tahu\", \"mbual\": \"bual\", \"tioghoa\": \"tionghoa\", \"ngentotin\": \"senggama\", \"kentot\": \"senggama\", \"faktakta\": \"fakta\", \"sohib\": \"teman\", \"rubahnn\": \"rubah\", \"trlalu\": \"terlalu\", \"nyela\": \"cela\", \"heters\": \"pembenci\", \"nyembah\": \"sembah\", \"most\": \"paling\", \"ikon\": \"lambang\", \"light\": \"terang\", \"pndukung\": \"pendukung\", \"setting\": \"atur\", \"seting\": \"akting\", \"next\": \"lanjut\", \"waspadalah\": \"waspada\", \"gantengsaya\": \"ganteng\", \"parte\": \"partai\", \"nyerang\": \"serang\", \"nipu\": \"tipu\", \"ktipu\": \"tipu\", \"jentelmen\": \"berani\", \"buangbuang\": \"buang\", \"tsangka\": \"tersangka\", \"kurng\": \"kurang\", \"ista\": \"nista\", \"less\": \"kurang\", \"koar\": \"teriak\", \"paranoid\": \"takut\", \"problem\": \"masalah\", \"tahi\": \"kotoran\", \"tirani\": \"tiran\", \"tilep\": \"tilap\", \"happy\": \"bahagia\", \"tak\": \"tidak\", \"penertiban\": \"tertib\", \"uasai\": \"kuasa\", \"mnolak\": \"tolak\", \"trending\": \"trend\", \"taik\": \"tahi\", \"wkwkwk\": \"tertawa\",\"wkwk\": \"tertawa\", \"ahokncc\": \"ahok\", \"istaa\": \"nista\", \"benarjujur\": \"jujur\", \"mgkin\": \"mungkin\", \"bundir\": \"bunuh diri\", \"org\": \"orang\", \"ga\": \"enggak\", \"gak\": \"enggak\", \"ku\": \"aku\", \"udh\": \"udah\", \"plz\": \"mohon\", \"health\": \"kesehatan\", \"smua\": \"semua\", \"lbh\": \"lebih\", \"smgt\": \"semangat\", \"mkn\": \"makin\", \"dibls\": \"dibalas\", \"ntah\": \"entah\", \"sdiri\": \"sendiri\", \"enk\": \"enak\", \"health\": \"kesehatan\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_abbreviations(text):\n",
    "    words = text.split()\n",
    "    abbreviated_words = [slang_words.get(word, word) for word in words]\n",
    "    return ' '.join(abbreviated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Username</th>\n",
       "      <th>Like Counts</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-02 20:59:07+00:00</td>\n",
       "      <td>Syar_bjm</td>\n",
       "      <td>3</td>\n",
       "      <td>@PangeranBiru212 @Samudera_Estu Knp hanya usta...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>knp hanya ustadz  knp bkn guru yg tdk cukup me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-10 04:50:26+00:00</td>\n",
       "      <td>Hazelnutxha</td>\n",
       "      <td>0</td>\n",
       "      <td>Replyannya bnrn darurat edukasi mental health ...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>replyannya bnrn darurat edukasi mental health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-14 22:44:42+00:00</td>\n",
       "      <td>wawanikip</td>\n",
       "      <td>0</td>\n",
       "      <td>Generasi melek mental health tapi gak ngerti a...</td>\n",
       "      <td>Youth</td>\n",
       "      <td>generasi melek mental health tapi gak ngerti a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20 08:12:15+00:00</td>\n",
       "      <td>minkabora</td>\n",
       "      <td>0</td>\n",
       "      <td>@indomyfess Logikanya, siapa yang bener2 berju...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>logikanya  siapa yang bener  berjuang  ga meny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 14:21:33+00:00</td>\n",
       "      <td>wipilarpa</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalau lingkungan kerjanya sama kaya yg di Band...</td>\n",
       "      <td>Others</td>\n",
       "      <td>kalau lingkungan kerjanya sama kaya yg di band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>2022-10-30 19:38:01+00:00</td>\n",
       "      <td>mbaimmmm</td>\n",
       "      <td>0</td>\n",
       "      <td>@simplybadut Pas udah tenang, dia cerita kalo ...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>pas udah tenang  dia cerita kalo dia udah bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>2022-11-19 09:29:03+00:00</td>\n",
       "      <td>collegemenfess</td>\n",
       "      <td>2</td>\n",
       "      <td>[cm] hii hii🙏maaf all disini aku mau minta tol...</td>\n",
       "      <td>Accessibility and Funding</td>\n",
       "      <td>cm  hii hii maaf all disini aku mau minta tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>2022-10-27 14:10:16+00:00</td>\n",
       "      <td>convomfs</td>\n",
       "      <td>6</td>\n",
       "      <td>🤍 tw mental health issues\\n\\nada yang tau ga k...</td>\n",
       "      <td>Accessibility and Funding</td>\n",
       "      <td>tw mental health issues  ada yang tau ga kal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>2022-12-19 17:48:42+00:00</td>\n",
       "      <td>UGM_FESS</td>\n",
       "      <td>30</td>\n",
       "      <td>Ugm_fess generasi kita yg paling keras teriak ...</td>\n",
       "      <td>Youth</td>\n",
       "      <td>ugm fess generasi kita yg paling keras teriak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>2022-12-10 02:46:03+00:00</td>\n",
       "      <td>bjorka171704</td>\n",
       "      <td>0</td>\n",
       "      <td>Gen Z nih pada kenapa ya? Teriak tentang menta...</td>\n",
       "      <td>Youth</td>\n",
       "      <td>gen z nih pada kenapa ya  teriak tentang menta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3828 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime        Username  Like Counts  \\\n",
       "0     2022-11-02 20:59:07+00:00        Syar_bjm            3   \n",
       "1     2022-11-10 04:50:26+00:00     Hazelnutxha            0   \n",
       "2     2022-11-14 22:44:42+00:00       wawanikip            0   \n",
       "3     2022-12-20 08:12:15+00:00       minkabora            0   \n",
       "4     2022-12-01 14:21:33+00:00       wipilarpa            0   \n",
       "...                         ...             ...          ...   \n",
       "3823  2022-10-30 19:38:01+00:00        mbaimmmm            0   \n",
       "3824  2022-11-19 09:29:03+00:00  collegemenfess            2   \n",
       "3825  2022-10-27 14:10:16+00:00        convomfs            6   \n",
       "3826  2022-12-19 17:48:42+00:00        UGM_FESS           30   \n",
       "3827  2022-12-10 02:46:03+00:00    bjorka171704            0   \n",
       "\n",
       "                                                  Tweet  \\\n",
       "0     @PangeranBiru212 @Samudera_Estu Knp hanya usta...   \n",
       "1     Replyannya bnrn darurat edukasi mental health ...   \n",
       "2     Generasi melek mental health tapi gak ngerti a...   \n",
       "3     @indomyfess Logikanya, siapa yang bener2 berju...   \n",
       "4     Kalau lingkungan kerjanya sama kaya yg di Band...   \n",
       "...                                                 ...   \n",
       "3823  @simplybadut Pas udah tenang, dia cerita kalo ...   \n",
       "3824  [cm] hii hii🙏maaf all disini aku mau minta tol...   \n",
       "3825  🤍 tw mental health issues\\n\\nada yang tau ga k...   \n",
       "3826  Ugm_fess generasi kita yg paling keras teriak ...   \n",
       "3827  Gen Z nih pada kenapa ya? Teriak tentang menta...   \n",
       "\n",
       "                              Class  \\\n",
       "0     Feelings and Problematization   \n",
       "1     Feelings and Problematization   \n",
       "2                             Youth   \n",
       "3     Feelings and Problematization   \n",
       "4                            Others   \n",
       "...                             ...   \n",
       "3823                 Classification   \n",
       "3824      Accessibility and Funding   \n",
       "3825      Accessibility and Funding   \n",
       "3826                          Youth   \n",
       "3827                          Youth   \n",
       "\n",
       "                                              cleanText  \n",
       "0     knp hanya ustadz  knp bkn guru yg tdk cukup me...  \n",
       "1     replyannya bnrn darurat edukasi mental health ...  \n",
       "2     generasi melek mental health tapi gak ngerti a...  \n",
       "3     logikanya  siapa yang bener  berjuang  ga meny...  \n",
       "4     kalau lingkungan kerjanya sama kaya yg di band...  \n",
       "...                                                 ...  \n",
       "3823  pas udah tenang  dia cerita kalo dia udah bias...  \n",
       "3824   cm  hii hii maaf all disini aku mau minta tol...  \n",
       "3825    tw mental health issues  ada yang tau ga kal...  \n",
       "3826  ugm fess generasi kita yg paling keras teriak ...  \n",
       "3827  gen z nih pada kenapa ya  teriak tentang menta...  \n",
       "\n",
       "[3828 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanTweets(text):\n",
    "    text = re.sub(r'@\\w+', '', text) \n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text) \n",
    "    text = re.sub('[^a-zA-Z]', ' ', str(text).lower().strip())\n",
    "    text = re.sub('#','',text)\n",
    "    text = re.sub('\\d+', '', text)\n",
    "    text = re.sub('[!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]+','', text) \n",
    "    text = re.sub('RT[\\s]+','',text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    return text\n",
    "data['cleanText'] = data['Tweet'].apply(cleanTweets) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleanText'] = data['cleanText'].apply(apply_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Username</th>\n",
       "      <th>Like Counts</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-02 20:59:07+00:00</td>\n",
       "      <td>Syar_bjm</td>\n",
       "      <td>3</td>\n",
       "      <td>@PangeranBiru212 @Samudera_Estu Knp hanya usta...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>ustadz mengajarkan budi pekerti polisi mengawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-10 04:50:26+00:00</td>\n",
       "      <td>Hazelnutxha</td>\n",
       "      <td>0</td>\n",
       "      <td>Replyannya bnrn darurat edukasi mental health ...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>replyannya bnrn darurat edukasi mental kesehat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-14 22:44:42+00:00</td>\n",
       "      <td>wawanikip</td>\n",
       "      <td>0</td>\n",
       "      <td>Generasi melek mental health tapi gak ngerti a...</td>\n",
       "      <td>Youth</td>\n",
       "      <td>generasi melek mental kesehatan mengerti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20 08:12:15+00:00</td>\n",
       "      <td>minkabora</td>\n",
       "      <td>0</td>\n",
       "      <td>@indomyfess Logikanya, siapa yang bener2 berju...</td>\n",
       "      <td>Feelings and Problematization</td>\n",
       "      <td>logikanya berjuang menyerah rendah hati engga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 14:21:33+00:00</td>\n",
       "      <td>wipilarpa</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalau lingkungan kerjanya sama kaya yg di Band...</td>\n",
       "      <td>Others</td>\n",
       "      <td>lingkungan kerjanya kaya bandung mah gakan pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>2022-10-30 19:38:01+00:00</td>\n",
       "      <td>mbaimmmm</td>\n",
       "      <td>0</td>\n",
       "      <td>@simplybadut Pas udah tenang, dia cerita kalo ...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>pas tenang cerita gitu akibat tekanan orgnya p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>2022-11-19 09:29:03+00:00</td>\n",
       "      <td>collegemenfess</td>\n",
       "      <td>2</td>\n",
       "      <td>[cm] hii hii🙏maaf all disini aku mau minta tol...</td>\n",
       "      <td>Accessibility and Funding</td>\n",
       "      <td>cm hii hii maaf tolong webinar kh tema webinar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>2022-10-27 14:10:16+00:00</td>\n",
       "      <td>convomfs</td>\n",
       "      <td>6</td>\n",
       "      <td>🤍 tw mental health issues\\n\\nada yang tau ga k...</td>\n",
       "      <td>Accessibility and Funding</td>\n",
       "      <td>mental kesehatan issues banget diajak bicara l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>2022-12-19 17:48:42+00:00</td>\n",
       "      <td>UGM_FESS</td>\n",
       "      <td>30</td>\n",
       "      <td>Ugm_fess generasi kita yg paling keras teriak ...</td>\n",
       "      <td>Youth</td>\n",
       "      <td>ugm generasi keras teriak mental kesehatan kem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>2022-12-10 02:46:03+00:00</td>\n",
       "      <td>bjorka171704</td>\n",
       "      <td>0</td>\n",
       "      <td>Gen Z nih pada kenapa ya? Teriak tentang menta...</td>\n",
       "      <td>Youth</td>\n",
       "      <td>teriak mental kesehatan lantang adab etika nol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3828 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime        Username  Like Counts  \\\n",
       "0     2022-11-02 20:59:07+00:00        Syar_bjm            3   \n",
       "1     2022-11-10 04:50:26+00:00     Hazelnutxha            0   \n",
       "2     2022-11-14 22:44:42+00:00       wawanikip            0   \n",
       "3     2022-12-20 08:12:15+00:00       minkabora            0   \n",
       "4     2022-12-01 14:21:33+00:00       wipilarpa            0   \n",
       "...                         ...             ...          ...   \n",
       "3823  2022-10-30 19:38:01+00:00        mbaimmmm            0   \n",
       "3824  2022-11-19 09:29:03+00:00  collegemenfess            2   \n",
       "3825  2022-10-27 14:10:16+00:00        convomfs            6   \n",
       "3826  2022-12-19 17:48:42+00:00        UGM_FESS           30   \n",
       "3827  2022-12-10 02:46:03+00:00    bjorka171704            0   \n",
       "\n",
       "                                                  Tweet  \\\n",
       "0     @PangeranBiru212 @Samudera_Estu Knp hanya usta...   \n",
       "1     Replyannya bnrn darurat edukasi mental health ...   \n",
       "2     Generasi melek mental health tapi gak ngerti a...   \n",
       "3     @indomyfess Logikanya, siapa yang bener2 berju...   \n",
       "4     Kalau lingkungan kerjanya sama kaya yg di Band...   \n",
       "...                                                 ...   \n",
       "3823  @simplybadut Pas udah tenang, dia cerita kalo ...   \n",
       "3824  [cm] hii hii🙏maaf all disini aku mau minta tol...   \n",
       "3825  🤍 tw mental health issues\\n\\nada yang tau ga k...   \n",
       "3826  Ugm_fess generasi kita yg paling keras teriak ...   \n",
       "3827  Gen Z nih pada kenapa ya? Teriak tentang menta...   \n",
       "\n",
       "                              Class  \\\n",
       "0     Feelings and Problematization   \n",
       "1     Feelings and Problematization   \n",
       "2                             Youth   \n",
       "3     Feelings and Problematization   \n",
       "4                            Others   \n",
       "...                             ...   \n",
       "3823                 Classification   \n",
       "3824      Accessibility and Funding   \n",
       "3825      Accessibility and Funding   \n",
       "3826                          Youth   \n",
       "3827                          Youth   \n",
       "\n",
       "                                              cleanText  \n",
       "0     ustadz mengajarkan budi pekerti polisi mengawa...  \n",
       "1     replyannya bnrn darurat edukasi mental kesehat...  \n",
       "2              generasi melek mental kesehatan mengerti  \n",
       "3     logikanya berjuang menyerah rendah hati engga ...  \n",
       "4     lingkungan kerjanya kaya bandung mah gakan pin...  \n",
       "...                                                 ...  \n",
       "3823  pas tenang cerita gitu akibat tekanan orgnya p...  \n",
       "3824  cm hii hii maaf tolong webinar kh tema webinar...  \n",
       "3825  mental kesehatan issues banget diajak bicara l...  \n",
       "3826  ugm generasi keras teriak mental kesehatan kem...  \n",
       "3827     teriak mental kesehatan lantang adab etika nol  \n",
       "\n",
       "[3828 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "import json\n",
    "\n",
    "\n",
    "with open('../dataset/stopwords_indonesia.json') as f:\n",
    "    data_id = json.load(f)\n",
    "\n",
    "data_stopwords = data_id['stopwords_indonesia']\n",
    "\n",
    "list_stopwords = stopwords.words('indonesian')\n",
    "\n",
    "english_words = set(words.words())\n",
    "\n",
    "list_stopwords.extend(english_words)\n",
    "list_stopwords.remove(\"mental\")\n",
    "\n",
    "list_stopwords = set(list_stopwords)\n",
    "\n",
    "additional_stopwords = data_stopwords\n",
    "list_stopwords.update(additional_stopwords)\n",
    "\n",
    "\n",
    "def removeStopwords(text):\n",
    "    text = [w for w in word_tokenize(text) if not w in list_stopwords]\n",
    "    return ' '.join(text)\n",
    "\n",
    "data['cleanText'] = data['cleanText'].apply(removeStopwords)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "\n",
    "def word_tokenize_wrapper(text, n):\n",
    "    gram = [' '.join(e) for e in nltk.ngrams(text.split(), n)]\n",
    "    return gram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceCalc(topics, tokenized_documents, dictionary, corpus):\n",
    "    coherence_model = CoherenceModel(topics=topics,\n",
    "                                     texts=tokenized_documents,\n",
    "                                     corpus=corpus,\n",
    "                                     dictionary=dictionary,\n",
    "                                     coherence='c_v')\n",
    "    coherence_values = coherence_model.get_coherence_per_topic()\n",
    "    return coherence_values\n",
    "\n",
    "def lda_model_with_coherence(data, total_topics, number_words):\n",
    "    data = data.tolist()\n",
    "    dictionary = corpora.Dictionary(data)\n",
    "    term_matrix = [dictionary.doc2bow(doc) for doc in data]\n",
    "\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(term_matrix, num_topics=total_topics, id2word=dictionary)\n",
    "\n",
    "    topics = lda_model.show_topics(num_topics=total_topics, num_words=number_words, formatted=False)\n",
    "    topic_keywords = [[word[0] for word in topic] for topic_idx, topic in topics]\n",
    "\n",
    "    coherence_values = coherenceCalc(topic_keywords, data, dictionary, term_matrix)\n",
    "\n",
    "    out = []\n",
    "    for i, (topic_idx, topic) in enumerate(topics):\n",
    "        topic_keywords = [word[0] for word in topic]\n",
    "        out.append({'topic_id': topic_idx, 'keywords': topic_keywords, 'coherence': coherence_values[i]})\n",
    "\n",
    "    return lda_model, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceCalc(topics, tokenized_documents, dictionary, corpus):\n",
    "    coherence_model = CoherenceModel(topics=topics,\n",
    "                                     texts=tokenized_documents,\n",
    "                                     corpus=corpus,\n",
    "                                     dictionary=dictionary,\n",
    "                                     coherence='c_v')\n",
    "    coherence_values = coherence_model.get_coherence_per_topic()\n",
    "    return coherence_values\n",
    "\n",
    "def lsi_model_with_coherence(data, total_topics, number_words):\n",
    "    data = data.tolist()\n",
    "    dictionary = corpora.Dictionary(data)\n",
    "    term_matrix = [dictionary.doc2bow(doc) for doc in data]\n",
    "\n",
    "    lsi_model = gensim.models.LsiModel(term_matrix, num_topics=total_topics, id2word=dictionary)\n",
    "\n",
    "    topics = lsi_model.show_topics(num_topics=total_topics, num_words=number_words, formatted=False)\n",
    "    topic_keywords = [[word[0] for word in topic] for topic_idx, topic in topics]\n",
    "\n",
    "    coherence_values = coherenceCalc(topic_keywords, data, dictionary, term_matrix)\n",
    "\n",
    "    out = []\n",
    "    for i, (topic_idx, topic) in enumerate(topics):\n",
    "        topic_keywords = [word[0] for word in topic]\n",
    "        out.append({'topic_id': topic_idx, 'keywords': topic_keywords, 'coherence': coherence_values[i]})\n",
    "\n",
    "    return lsi_model, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceCalc(topics, tokenized_documents, dictionary, corpus):\n",
    "    coherence_model = CoherenceModel(topics=topics,\n",
    "                                     texts=tokenized_documents,\n",
    "                                     corpus=corpus,\n",
    "                                     dictionary=dictionary,\n",
    "                                     coherence='c_v')\n",
    "    coherence_values = coherence_model.get_coherence_per_topic()\n",
    "    return coherence_values\n",
    "\n",
    "def hdp_model_with_coherence(data, total_topics, number_words):\n",
    "    data = data.tolist()\n",
    "    dictionary = corpora.Dictionary(data)\n",
    "    term_matrix = [dictionary.doc2bow(doc) for doc in data]\n",
    "\n",
    "    hdp_model = gensim.models.HdpModel(term_matrix, id2word=dictionary)\n",
    "\n",
    "    topics = hdp_model.show_topics(num_topics=total_topics, num_words=number_words, formatted=False)\n",
    "    topic_keywords = [[word[0] for word in topic] for topic_idx, topic in topics]\n",
    "\n",
    "    coherence_values = coherenceCalc(topic_keywords, data, dictionary, term_matrix)\n",
    "\n",
    "    out = []\n",
    "    for i, (topic_idx, topic) in enumerate(topics):\n",
    "        topic_keywords = [word[0] for word in topic]\n",
    "        out.append({'topic_id': topic_idx, 'keywords': topic_keywords, 'coherence': coherence_values[i]})\n",
    "\n",
    "    return hdp_model, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def worldCloud(listData):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    wc = WordCloud(max_words=1000, width=1600, height=800, background_color='white').generate(\" \".join(listData))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 3\n",
    "number_words = 10\n",
    "\n",
    "lda_model, topics_data = lda_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>importance</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mental</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kesehatan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071463</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banget</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dikit</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kuliah</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anak</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>emang</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kerja</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bikin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tertawa</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  topic_id  importance  word_count\n",
       "0     mental         0    0.074889         957\n",
       "1  kesehatan         0    0.071463         913\n",
       "2     banget         0    0.010555         134\n",
       "3      dikit         0    0.008676         110\n",
       "4     kuliah         0    0.005082          64\n",
       "5       anak         0    0.004457          56\n",
       "6      emang         0    0.004222          53\n",
       "7      kerja         0    0.004066          51\n",
       "8      bikin         0    0.004066          51\n",
       "9    tertawa         0    0.003831          48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "lda_model, topics_data = lda_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>importance</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kesehatan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062191</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mental</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061932</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psikolog</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bantuan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009069</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kasih</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psikiater</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>layanan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>konsul</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>banget</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>terima</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  topic_id  importance  word_count\n",
       "0  kesehatan         0    0.062191         239\n",
       "1     mental         0    0.061932         238\n",
       "2   psikolog         0    0.018397          70\n",
       "3    bantuan         0    0.009069          34\n",
       "4      kasih         0    0.007773          29\n",
       "5  psikiater         0    0.007773          29\n",
       "6    layanan         0    0.006737          25\n",
       "7     konsul         0    0.006478          24\n",
       "8     banget         0    0.006219          23\n",
       "9     terima         0    0.006219          23"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 7\n",
    "number_words = 10\n",
    "\n",
    "lda_model, topics_data = lda_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>importance</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mental</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702564</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kesehatan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689803</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banget</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menjaga</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jaga</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046747</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fisik</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041146</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hidup</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anak</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kerja</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024972</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bikin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022952</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  topic_id  importance  word_count\n",
       "0     mental         0    0.702564         915\n",
       "1  kesehatan         0    0.689803         904\n",
       "2     banget         0    0.055259          70\n",
       "3    menjaga         0    0.051062          63\n",
       "4       jaga         0    0.046747          61\n",
       "5      fisik         0    0.041146          51\n",
       "6      hidup         0    0.030371          40\n",
       "7       anak         0    0.027009          31\n",
       "8      kerja         0    0.024972          34\n",
       "9      bikin         0    0.022952          31"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 3\n",
    "number_words = 10\n",
    "\n",
    "lsi_model, topics_data = lsi_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>importance</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mental</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709054</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kesehatan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666388</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banget</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094845</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dikit</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084255</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kuliah</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049929</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anak</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037854</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bawa</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bikin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036612</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>emang</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036110</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kerja</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035625</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  topic_id  importance  word_count\n",
       "0     mental         0    0.709054         957\n",
       "1  kesehatan         0    0.666388         913\n",
       "2     banget         0    0.094845         134\n",
       "3      dikit         0    0.084255         110\n",
       "4     kuliah         0    0.049929          64\n",
       "5       anak         0    0.037854          56\n",
       "6       bawa         0    0.036626          44\n",
       "7      bikin         0    0.036612          51\n",
       "8      emang         0    0.036110          53\n",
       "9      kerja         0    0.035625          51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "lsi_model, topics_data = lsi_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>importance</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kesehatan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659166</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mental</td>\n",
       "      <td>0</td>\n",
       "      <td>0.651896</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psikolog</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204022</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bantuan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099169</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>psikiater</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kasih</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083548</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>terima</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067217</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>konsul</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066290</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>layanan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064841</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>banget</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060397</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  topic_id  importance  word_count\n",
       "0  kesehatan         0    0.659166         239\n",
       "1     mental         0    0.651896         238\n",
       "2   psikolog         0    0.204022          70\n",
       "3    bantuan         0    0.099169          34\n",
       "4  psikiater         0    0.091257          29\n",
       "5      kasih         0    0.083548          29\n",
       "6     terima         0    0.067217          23\n",
       "7     konsul         0    0.066290          24\n",
       "8    layanan         0    0.064841          25\n",
       "9     banget         0    0.060397          23"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 7\n",
    "number_words = 10\n",
    "\n",
    "lsi_model, topics_data = lsi_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>importance</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nama</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kesulitan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anak</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pentinh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>isi</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>keputusan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nugas</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tips</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>terekspose</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bermanfaat</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  topic_id  importance  word_count\n",
       "0        nama         0    0.002721           3\n",
       "1   kesulitan         0    0.002574           2\n",
       "2        anak         0    0.002498          31\n",
       "3     pentinh         0    0.002496           1\n",
       "4         isi         0    0.002425           4\n",
       "5   keputusan         0    0.002349           7\n",
       "6       nugas         0    0.002293           1\n",
       "7        tips         0    0.002174           1\n",
       "8  terekspose         0    0.002126           1\n",
       "9  bermanfaat         0    0.002118           1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 3\n",
    "number_words = 10\n",
    "\n",
    "hdp_model, topics_data = hdp_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>importance</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kesehatan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mental</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relawan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kelompokin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gatau</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>brati</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nnt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bikin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>banget</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>menurutku</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  topic_id  importance  word_count\n",
       "0   kesehatan         0    0.004402         913\n",
       "1      mental         0    0.003041         957\n",
       "2     relawan         0    0.002674           1\n",
       "3  kelompokin         0    0.002666           1\n",
       "4       gatau         0    0.002162          11\n",
       "5       brati         0    0.002107           1\n",
       "6         nnt         0    0.001985           2\n",
       "7       bikin         0    0.001949          51\n",
       "8      banget         0    0.001862         134\n",
       "9   menurutku         0    0.001855           2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "hdp_model, topics_data = hdp_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>importance</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silakan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sulit</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kasih</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rw</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>solusi</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guis</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>catatan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dipendem</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>didengar</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  topic_id  importance  word_count\n",
       "0   silakan         0    0.006864           1\n",
       "1     sulit         0    0.005783           1\n",
       "2        rt         0    0.005609           1\n",
       "3     kasih         0    0.005564          29\n",
       "4        rw         0    0.005252           1\n",
       "5    solusi         0    0.005185           2\n",
       "6      guis         0    0.004572           1\n",
       "7   catatan         0    0.004499           1\n",
       "8  dipendem         0    0.004437           1\n",
       "9  didengar         0    0.004422           1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean = data['cleanText'].apply(word_tokenize_wrapper, n=1)\n",
    "total_topics = 7\n",
    "number_words = 10\n",
    "\n",
    "hdp_model, topics_data = hdp_model_with_coherence(doc_clean, total_topics, number_words)\n",
    "\n",
    "for topic in topics_data:\n",
    "    print('Topic ID:', topic['topic_id'], '| Keywords:', topic['keywords'], '| Coherence Score:', topic['coherence'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
